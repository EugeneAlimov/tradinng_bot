#!/usr/bin/env python3
"""üßπ –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –æ—á–∏—Å—Ç–∫–∏ —Ç–æ—Ä–≥–æ–≤–æ–≥–æ –±–æ—Ç–∞ –æ—Ç –º—É—Å–æ—Ä–∞ v2.0"""

import os
import shutil
import json
import glob
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Set
import logging


class BotCleaner:
    """üßπ –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ —Ç–æ—Ä–≥–æ–≤–æ–≥–æ –±–æ—Ç–∞ –æ—Ç –º—É—Å–æ—Ä–∞"""

    def __init__(self):
        self.root_dir = Path(".")
        self.logger = self._setup_logger()

        # –¶–≤–µ—Ç–æ–≤—ã–µ –∫–æ–¥—ã –¥–ª—è –≤—ã–≤–æ–¥–∞
        self.GREEN = "\033[92m"
        self.RED = "\033[91m"
        self.YELLOW = "\033[93m"
        self.BLUE = "\033[94m"
        self.CYAN = "\033[96m"
        self.END = "\033[0m"

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—á–∏—Å—Ç–∫–∏
        self.stats = {
            'files_removed': 0,
            'directories_removed': 0,
            'bytes_freed': 0,
            'duplicates_removed': 0,
            'migration_artifacts_removed': 0
        }

    def _setup_logger(self):
        """üìù –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('cleanup_v2.log'),
                logging.StreamHandler()
            ]
        )
        return logging.getLogger(__name__)

    def analyze_updated_project(self) -> Dict[str, List[str]]:
        """üîç –ê–Ω–∞–ª–∏–∑ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞"""
        print(f"{self.BLUE}üîç –ê–Ω–∞–ª–∏–∑ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞...{self.END}")

        analysis = {
            'migration_artifacts': [],
            'backup_directories': [],
            'duplicate_files': [],
            'old_patch_files': [],
            'temp_files': [],
            'broken_migrations': [],
            'outdated_configs': [],
            'unused_scripts': [],
            'log_files': [],
            'cache_files': []
        }

        # –ü–æ–∏—Å–∫ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –º–∏–≥—Ä–∞—Ü–∏–∏ (–æ—Å–Ω–æ–≤–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞)
        analysis['migration_artifacts'] = self._find_migration_artifacts()

        # –ü–æ–∏—Å–∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –±—ç–∫–∞–ø–æ–≤
        analysis['backup_directories'] = self._find_backup_directories()

        # –ü–æ–∏—Å–∫ –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è —Ñ–∞–π–ª–æ–≤
        analysis['duplicate_files'] = self._find_duplicate_files()

        # –ü–æ–∏—Å–∫ —Å—Ç–∞—Ä—ã—Ö –ø–∞—Ç—á–µ–π
        analysis['old_patch_files'] = self._find_old_patch_files()

        # –ü–æ–∏—Å–∫ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        analysis['temp_files'] = self._find_temp_files()

        # –ü–æ–∏—Å–∫ —Å–ª–æ–º–∞–Ω–Ω—ã—Ö –º–∏–≥—Ä–∞—Ü–∏–π
        analysis['broken_migrations'] = self._find_broken_migrations()

        # –ü–æ–∏—Å–∫ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –∫–æ–Ω—Ñ–∏–≥–æ–≤
        analysis['outdated_configs'] = self._find_outdated_configs()

        # –ü–æ–∏—Å–∫ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö —Å–∫—Ä–∏–ø—Ç–æ–≤
        analysis['unused_scripts'] = self._find_unused_scripts()

        # –ü–æ–∏—Å–∫ –ª–æ–≥ —Ñ–∞–π–ª–æ–≤
        analysis['log_files'] = self._find_log_files()

        # –ü–æ–∏—Å–∫ –∫—ç—à —Ñ–∞–π–ª–æ–≤
        analysis['cache_files'] = self._find_cache_files()

        return analysis

    def _find_migration_artifacts(self) -> List[str]:
        """üîç –ü–æ–∏—Å–∫ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –º–∏–≥—Ä–∞—Ü–∏–∏ (–≥–ª–∞–≤–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞)"""
        artifacts = []

        # –§–∞–π–ª—ã –ø–∞—Ç—á–µ–π –º–∏–≥—Ä–∞—Ü–∏–∏
        migration_patterns = [
            'migration_patch.py',
            'auto_fix_patch.py',
            'migration_part*.py',
            'migration_instructions.py',
            'migration_executor.py',
            'system_check.py',
            'diagnostic_report.json',
            'cleanup*.log'
        ]

        for pattern in migration_patterns:
            files = glob.glob(str(self.root_dir / pattern))
            artifacts.extend([str(Path(f).relative_to(self.root_dir)) for f in files])

        return artifacts

    def _find_backup_directories(self) -> List[str]:
        """üîç –ü–æ–∏—Å–∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –±—ç–∫–∞–ø–æ–≤"""
        backup_dirs = []

        # –ò–∑–≤–µ—Å—Ç–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –±—ç–∫–∞–ø–æ–≤
        backup_dir_names = [
            'backup_before_migration',
            'cleanup_backup_*',
            'old_files',
            'backups'
        ]

        for pattern in backup_dir_names:
            dirs = glob.glob(str(self.root_dir / pattern))
            backup_dirs.extend([str(Path(d).relative_to(self.root_dir)) for d in dirs if Path(d).is_dir()])

        return backup_dirs

    def _find_duplicate_files(self) -> List[Dict[str, str]]:
        """üîç –ü–æ–∏—Å–∫ –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è —Ñ–∞–π–ª–æ–≤ –≤ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ"""
        duplicates = []

        # –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –¥—É–±–ª–∏–∫–∞—Ç—ã
        known_duplicates = [
            ('main.py', 'main_old.py', 'Legacy main —Ñ–∞–π–ª'),
            ('bot.py', 'hybrid_bot.py', 'Hybrid –±–æ—Ç –≤–µ—Ä—Å–∏—è'),
            ('config.py', 'hybrid_config.py', 'Hybrid –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è'),
            ('README.md', 'README_NEW.md', '–ù–æ–≤–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è'),
            ('position_summary.json', 'position_summary_*.json', '–°—Ç–∞—Ä—ã–µ summary —Ñ–∞–π–ª—ã')
        ]

        for original, duplicate_pattern, reason in known_duplicates:
            if (self.root_dir / original).exists():
                # –ò—â–µ–º —Ñ–∞–π–ª—ã –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É
                duplicate_files = glob.glob(str(self.root_dir / duplicate_pattern))
                for dup_file in duplicate_files:
                    if Path(dup_file).exists():
                        duplicates.append({
                            'original': original,
                            'duplicate': str(Path(dup_file).relative_to(self.root_dir)),
                            'reason': reason
                        })

        return duplicates

    def _find_old_patch_files(self) -> List[str]:
        """üîç –ü–æ–∏—Å–∫ —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤ –ø–∞—Ç—á–µ–π"""
        patch_files = []

        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã —Ñ–∞–π–ª–æ–≤ –ø–∞—Ç—á–µ–π
        patch_patterns = [
            '*_patch.py',
            'patch_*.py',
            'fix_*.py',
            'auto_*.py',
            'migration_*.py'
        ]

        for pattern in patch_patterns:
            files = glob.glob(str(self.root_dir / pattern))
            patch_files.extend([str(Path(f).relative_to(self.root_dir)) for f in files])

        return patch_files

    def _find_broken_migrations(self) -> List[str]:
        """üîç –ü–æ–∏—Å–∫ —Å–ª–æ–º–∞–Ω–Ω—ã—Ö –º–∏–≥—Ä–∞—Ü–∏–π"""
        broken = []

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º src/ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –Ω–∞ –Ω–µ–ø–æ–ª–Ω—ã–µ –º–∏–≥—Ä–∞—Ü–∏–∏
        src_dir = self.root_dir / "src"
        if src_dir.exists():
            # –ò—â–µ–º –ø—É—Å—Ç—ã–µ __init__.py —Ñ–∞–π–ª—ã
            for init_file in src_dir.rglob("__init__.py"):
                try:
                    content = init_file.read_text()
                    if content.strip() == '"""üì¶ –ú–æ–¥—É–ª—å —Ç–æ—Ä–≥–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã"""':
                        broken.append(str(init_file.relative_to(self.root_dir)))
                except:
                    pass

        return broken

    def _find_outdated_configs(self) -> List[str]:
        """üîç –ü–æ–∏—Å–∫ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π"""
        outdated = []

        # –°—Ç–∞—Ä—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        old_config_patterns = [
            'hybrid_config.py',
            'config_old.py',
            'settings_old.py',
            '.env.old',
            '.env.backup'
        ]

        for pattern in old_config_patterns:
            files = glob.glob(str(self.root_dir / pattern))
            outdated.extend([str(Path(f).relative_to(self.root_dir)) for f in files])

        return outdated

    def _find_unused_scripts(self) -> List[str]:
        """üîç –ü–æ–∏—Å–∫ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö —Å–∫—Ä–∏–ø—Ç–æ–≤"""
        unused = []

        # –£—Ç–∏–ª–∏—Ç–∞—Ä–Ω—ã–µ —Å–∫—Ä–∏–ø—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–µ –Ω—É–∂–Ω—ã
        utility_scripts = [
            'trades_manager.py',
            'system_check.py',
            'test_*.py',
            'check_*.py',
            'analyze_*.py'
        ]

        for pattern in utility_scripts:
            files = glob.glob(str(self.root_dir / pattern))
            unused.extend([str(Path(f).relative_to(self.root_dir)) for f in files])

        return unused

    def _find_temp_files(self) -> List[str]:
        """üîç –ü–æ–∏—Å–∫ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        temp_files = []

        # –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        temp_patterns = [
            '*.tmp',
            '*.temp',
            '*.pyc',
            '__pycache__/*',
            '.DS_Store',
            'Thumbs.db',
            '*.swp',
            '*.swo',
            '*~',
            '.pytest_cache/*'
        ]

        for pattern in temp_patterns:
            files = glob.glob(str(self.root_dir / pattern), recursive=True)
            temp_files.extend([str(Path(f).relative_to(self.root_dir)) for f in files])

        return temp_files

    def _find_log_files(self) -> List[str]:
        """üîç –ü–æ–∏—Å–∫ —Å—Ç–∞—Ä—ã—Ö –ª–æ–≥ —Ñ–∞–π–ª–æ–≤"""
        log_files = []

        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –ª–æ–≥ —Ñ–∞–π–ª–æ–≤
        log_patterns = [
            '*.log',
            '*.log.*',
            'logs/*.log.*',
            'cleanup*.log'
        ]

        for pattern in log_patterns:
            files = glob.glob(str(self.root_dir / pattern), recursive=True)
            log_files.extend([str(Path(f).relative_to(self.root_dir)) for f in files])

        return log_files

    def _find_cache_files(self) -> List[str]:
        """üîç –ü–æ–∏—Å–∫ –∫—ç—à —Ñ–∞–π–ª–æ–≤"""
        cache_files = []

        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –∫—ç—à —Ñ–∞–π–ª–æ–≤
        cache_patterns = [
            '__pycache__',
            '*.pyc',
            '.pytest_cache'
        ]

        for pattern in cache_patterns:
            files = glob.glob(str(self.root_dir / "**" / pattern), recursive=True)
            cache_files.extend([str(Path(f).relative_to(self.root_dir)) for f in files])

        return cache_files

    def show_updated_analysis_report(self, analysis: Dict[str, List]) -> None:
        """üìã –ü–æ–∫–∞–∑ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞"""
        print(f"\n{self.CYAN}üìã –û–¢–ß–ï–¢ –ê–ù–ê–õ–ò–ó–ê –û–ë–ù–û–í–õ–ï–ù–ù–û–ì–û –ü–†–û–ï–ö–¢–ê{self.END}")
        print("=" * 50)

        categories = [
            ('migration_artifacts', '–ê—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –º–∏–≥—Ä–∞—Ü–∏–∏', 'üîÑ', 'red'),
            ('backup_directories', '–î–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –±—ç–∫–∞–ø–æ–≤', 'üì¶', 'yellow'),
            ('duplicate_files', '–î—É–±–ª–∏–∫–∞—Ç—ã —Ñ–∞–π–ª–æ–≤', 'üîÑ', 'yellow'),
            ('old_patch_files', '–°—Ç–∞—Ä—ã–µ –ø–∞—Ç—á–∏', 'üîß', 'yellow'),
            ('broken_migrations', '–°–ª–æ–º–∞–Ω–Ω—ã–µ –º–∏–≥—Ä–∞—Ü–∏–∏', 'üí•', 'red'),
            ('outdated_configs', '–£—Å—Ç–∞—Ä–µ–≤—à–∏–µ –∫–æ–Ω—Ñ–∏–≥–∏', '‚öôÔ∏è', 'yellow'),
            ('unused_scripts', '–ù–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —Å–∫—Ä–∏–ø—Ç—ã', 'üìú', 'blue'),
            ('temp_files', '–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã', 'üóëÔ∏è', 'green'),
            ('log_files', '–õ–æ–≥ —Ñ–∞–π–ª—ã', 'üìã', 'blue'),
            ('cache_files', '–ö—ç—à —Ñ–∞–π–ª—ã', 'üíæ', 'green')
        ]

        total_issues = 0
        critical_issues = 0

        for key, title, emoji, priority in categories:
            items = analysis[key]
            if items:
                color = self.RED if priority == 'red' else self.YELLOW if priority == 'yellow' else self.BLUE if priority == 'blue' else self.GREEN
                print(f"\n{color}{emoji} {title}: {len(items)}{self.END}")

                if priority == 'red':
                    critical_issues += len(items)

                if key == 'duplicate_files':
                    for item in items[:5]:
                        print(f"  ‚Ä¢ {item['duplicate']} (–¥—É–±–ª–∏–∫–∞—Ç {item['original']}) - {item['reason']}")
                    if len(items) > 5:
                        print(f"  ... –∏ –µ—â–µ {len(items) - 5} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
                else:
                    for item in items[:8]:
                        print(f"  ‚Ä¢ {item}")
                    if len(items) > 8:
                        print(f"  ... –∏ –µ—â–µ {len(items) - 8} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")

                total_issues += len(items)
            else:
                print(f"{emoji} {title}: ‚úÖ –ß–∏—Å—Ç–æ")

        print(f"\n{'=' * 50}")
        print(f"–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º: {total_issues}")
        if critical_issues > 0:
            print(f"{self.RED}–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º: {critical_issues}{self.END}")

        if total_issues > 0:
            print(f"{self.YELLOW}üí° –ù–∞—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Å—Ç–∏ –æ—á–∏—Å—Ç–∫—É{self.END}")
            if critical_issues > 0:
                print(f"{self.RED}‚ö†Ô∏è –ù–∞–π–¥–µ–Ω—ã –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã –º–∏–≥—Ä–∞—Ü–∏–∏!{self.END}")
        else:
            print(f"{self.GREEN}üéâ –ü—Ä–æ–µ–∫—Ç —á–∏—Å—Ç—ã–π!{self.END}")

    def clean_updated_project(self, analysis: Dict[str, List], interactive: bool = True) -> None:
        """üßπ –û—á–∏—Å—Ç–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞"""
        print(f"{self.YELLOW}üßπ –ù–∞—á–∏–Ω–∞–µ–º –æ—á–∏—Å—Ç–∫—É –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞...{self.END}")

        # –°–æ–∑–¥–∞–µ–º –±—ç–∫–∞–ø –ø–µ—Ä–µ–¥ –æ—á–∏—Å—Ç–∫–æ–π
        if interactive:
            create_backup = input(f"{self.BLUE}üíæ –°–æ–∑–¥–∞—Ç—å –±—ç–∫–∞–ø –ø–µ—Ä–µ–¥ –æ—á–∏—Å—Ç–∫–æ–π? (Y/n): {self.END}").lower()
            if create_backup != 'n':
                self._create_cleanup_backup()

        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ - —Å–Ω–∞—á–∞–ª–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã
        priority_order = [
            ('migration_artifacts', '–ê—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –º–∏–≥—Ä–∞—Ü–∏–∏'),
            ('old_patch_files', '–°—Ç–∞—Ä—ã–µ –ø–∞—Ç—á–∏'),
            ('broken_migrations', '–°–ª–æ–º–∞–Ω–Ω—ã–µ –º–∏–≥—Ä–∞—Ü–∏–∏'),
            ('backup_directories', '–î–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –±—ç–∫–∞–ø–æ–≤'),
            ('duplicate_files', '–î—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è —Ñ–∞–π–ª—ã'),
            ('temp_files', '–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã'),
            ('cache_files', '–ö—ç—à —Ñ–∞–π–ª—ã'),
            ('outdated_configs', '–£—Å—Ç–∞—Ä–µ–≤—à–∏–µ –∫–æ–Ω—Ñ–∏–≥–∏'),
            ('log_files', '–°—Ç–∞—Ä—ã–µ –ª–æ–≥–∏')
        ]

        for category, title in priority_order:
            if analysis[category]:
                self._clean_category(category, title, analysis[category], interactive)

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self._show_cleanup_stats()

    def _clean_category(self, category: str, title: str, items: List, interactive: bool) -> None:
        """üßπ –û—á–∏—Å—Ç–∫–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
        if not items:
            return

        print(f"\n{self.YELLOW}üßπ –û—á–∏—Å—Ç–∫–∞: {title} ({len(items)} –Ω–∞–π–¥–µ–Ω–æ){self.END}")

        if interactive:
            print(f"–ù–∞–π–¥–µ–Ω—ã —ç–ª–µ–º–µ–Ω—Ç—ã –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{title}':")
            for item in items[:10]:
                if isinstance(item, dict):
                    print(f"  ‚Ä¢ {item.get('duplicate', item)} ({item.get('reason', '–¥—É–±–ª–∏–∫–∞—Ç')})")
                else:
                    print(f"  ‚Ä¢ {item}")
            if len(items) > 10:
                print(f"  ... –∏ –µ—â–µ {len(items) - 10} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")

            confirm = input(f"{self.BLUE}–û—á–∏—Å—Ç–∏—Ç—å {title.lower()}? (Y/n): {self.END}").lower()
            if confirm == 'n':
                return

        # –û—á–∏—â–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã
        for item in items:
            try:
                if isinstance(item, dict):
                    item_path = self.root_dir / item['duplicate']
                else:
                    item_path = self.root_dir / item

                if item_path.exists():
                    if item_path.is_file():
                        size = item_path.stat().st_size
                        item_path.unlink()
                        self.stats['files_removed'] += 1
                        self.stats['bytes_freed'] += size

                        if category == 'migration_artifacts':
                            self.stats['migration_artifacts_removed'] += 1
                        elif category == 'duplicate_files':
                            self.stats['duplicates_removed'] += 1

                    elif item_path.is_dir():
                        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
                        total_size = sum(f.stat().st_size for f in item_path.rglob('*') if f.is_file())
                        shutil.rmtree(item_path)
                        self.stats['directories_removed'] += 1
                        self.stats['bytes_freed'] += total_size

                    print(f"  ‚úÖ –£–¥–∞–ª–µ–Ω: {item}")

            except Exception as e:
                print(f"  ‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è {item}: {e}")

    def _create_cleanup_backup(self) -> None:
        """üíæ –°–æ–∑–¥–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞ –ø–µ—Ä–µ–¥ –æ—á–∏—Å—Ç–∫–æ–π"""
        backup_dir = self.root_dir / f"cleanup_backup_v2_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        backup_dir.mkdir(exist_ok=True)

        # –ö–æ–ø–∏—Ä—É–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω—ã–µ —Ñ–∞–π–ª—ã
        important_files = [
            'main.py',
            'bot.py',
            'config.py',
            'requirements.txt',
            '.env*',
            'README*.md',
            'data/*',
            'logs/*'
        ]

        for pattern in important_files:
            files = glob.glob(str(self.root_dir / pattern))
            for file_path in files:
                if Path(file_path).is_file():
                    rel_path = Path(file_path).relative_to(self.root_dir)
                    dest_path = backup_dir / rel_path
                    dest_path.parent.mkdir(parents=True, exist_ok=True)
                    shutil.copy2(file_path, dest_path)

        print(f"{self.GREEN}üíæ –ë—ç–∫–∞–ø —Å–æ–∑–¥–∞–Ω: {backup_dir}{self.END}")

    def _show_cleanup_stats(self) -> None:
        """üìä –ü–æ–∫–∞–∑ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ—á–∏—Å—Ç–∫–∏"""
        print(f"\n{self.GREEN}üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –û–ß–ò–°–¢–ö–ò v2.0{self.END}")
        print("=" * 35)
        print(f"–£–¥–∞–ª–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {self.stats['files_removed']}")
        print(f"–£–¥–∞–ª–µ–Ω–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π: {self.stats['directories_removed']}")
        print(f"–£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {self.stats['duplicates_removed']}")
        print(f"–£–¥–∞–ª–µ–Ω–æ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –º–∏–≥—Ä–∞—Ü–∏–∏: {self.stats['migration_artifacts_removed']}")
        print(f"–û—Å–≤–æ–±–æ–∂–¥–µ–Ω–æ –º–µ—Å—Ç–∞: {self.stats['bytes_freed'] / (1024 * 1024):.2f} MB")

        if self.stats['migration_artifacts_removed'] > 0:
            print(f"{self.GREEN}‚ú® –ü—Ä–æ–µ–∫—Ç –æ—á–∏—â–µ–Ω –æ—Ç –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –º–∏–≥—Ä–∞—Ü–∏–∏!{self.END}")

    def create_project_health_report(self, analysis: Dict[str, List]) -> None:
        """üìã –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –æ –∑–¥–æ—Ä–æ–≤—å–µ –ø—Ä–æ–µ–∫—Ç–∞"""
        report_data = {
            'timestamp': datetime.now().isoformat(),
            'total_issues': sum(len(items) for items in analysis.values()),
            'critical_issues': len(analysis['migration_artifacts']) + len(analysis['broken_migrations']),
            'categories': {k: len(v) for k, v in analysis.items()},
            'recommendations': []
        }

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if analysis['migration_artifacts']:
            report_data['recommendations'].append("–£–¥–∞–ª–∏—Ç–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –º–∏–≥—Ä–∞—Ü–∏–∏ –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –ø—Ä–æ–µ–∫—Ç–∞")

        if analysis['backup_directories']:
            report_data['recommendations'].append("–ê—Ä—Ö–∏–≤–∏—Ä—É–π—Ç–µ –∏–ª–∏ —É–¥–∞–ª–∏—Ç–µ —Å—Ç–∞—Ä—ã–µ –±—ç–∫–∞–ø—ã")

        if analysis['duplicate_files']:
            report_data['recommendations'].append("–£–¥–∞–ª–∏—Ç–µ –¥—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è —Ñ–∞–π–ª—ã")

        if not report_data['recommendations']:
            report_data['recommendations'].append("–ü—Ä–æ–µ–∫—Ç –≤ —Ö–æ—Ä–æ—à–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏!")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
        with open('project_health_report.json', 'w') as f:
            json.dump(report_data, f, indent=2)

        print(f"{self.GREEN}üìã –û—Ç—á–µ—Ç –æ –∑–¥–æ—Ä–æ–≤—å–µ –ø—Ä–æ–µ–∫—Ç–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: project_health_report.json{self.END}")

    def run_updated_interactive_cleanup(self) -> None:
        """üöÄ –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞"""
        print(f"{self.CYAN}üßπ –ò–ù–¢–ï–†–ê–ö–¢–ò–í–ù–ê–Ø –û–ß–ò–°–¢–ö–ê –¢–û–†–ì–û–í–û–ì–û –ë–û–¢–ê v2.0{self.END}")
        print("=" * 55)
        print(f"{self.YELLOW}üîÑ –ê–Ω–∞–ª–∏–∑ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞ –ø–æ—Å–ª–µ –º–∏–≥—Ä–∞—Ü–∏–∏{self.END}")

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –ø—Ä–æ–µ–∫—Ç
        analysis = self.analyze_updated_project()

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Ç—á–µ—Ç
        self.show_updated_analysis_report(analysis)

        # –°–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç –æ –∑–¥–æ—Ä–æ–≤—å–µ
        self.create_project_health_report(analysis)

        # –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º –æ—á–∏—Å—Ç–∫—É
        total_issues = sum(len(items) for items in analysis.values())
        critical_issues = len(analysis['migration_artifacts']) + len(analysis['broken_migrations'])

        if total_issues > 0:
            print(f"\n{self.YELLOW}–ù–∞–π–¥–µ–Ω–æ {total_issues} –ø—Ä–æ–±–ª–µ–º –¥–ª—è –æ—á–∏—Å—Ç–∫–∏{self.END}")
            if critical_issues > 0:
                print(f"{self.RED}‚ö†Ô∏è –ò–∑ –Ω–∏—Ö {critical_issues} –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö!{self.END}")

            proceed = input(f"{self.BLUE}–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Å –æ—á–∏—Å—Ç–∫–æ–π? (Y/n): {self.END}").lower()

            if proceed != 'n':
                self.clean_updated_project(analysis, interactive=True)

                # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
                print(f"\n{self.GREEN}üéâ –û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!{self.END}")
                print(f"{self.BLUE}üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏:{self.END}")
                print("  1. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –ø—Ä–æ–µ–∫—Ç: python main.py")
                print("  2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –≤—Å–µ—Ö —Ä–µ–∂–∏–º–æ–≤")
                print("  3. –£–¥–∞–ª–∏—Ç–µ project_health_report.json –ø–æ—Å–ª–µ –ø—Ä–æ–≤–µ—Ä–∫–∏")
            else:
                print("–û—á–∏—Å—Ç–∫–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞")
        else:
            print(f"{self.GREEN}–ü—Ä–æ–µ–∫—Ç —É–∂–µ —á–∏—Å—Ç—ã–π! üéâ{self.END}")

    def run_interactive_cleanup(self) -> None:
        """üöÄ –ê–ª–∏–∞—Å –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏"""
        self.run_updated_interactive_cleanup()


def main():
    """üöÄ –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–π –æ—á–∏—Å—Ç–∫–∏"""
    cleaner = BotCleaner()

    try:
        cleaner.run_updated_interactive_cleanup()
    except KeyboardInterrupt:
        print(f"\n{cleaner.YELLOW}‚å®Ô∏è –û—á–∏—Å—Ç–∫–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º{cleaner.END}")
    except Exception as e:
        print(f"\n{cleaner.RED}‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏: {e}{cleaner.END}")
        cleaner.logger.error(f"Cleanup error: {e}")


if __name__ == "__main__":
    main()


    def _setup_logger(self):
        """üìù –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('cleanup.log'),
                logging.StreamHandler()
            ]
        )
        return logging.getLogger(__name__)


    def analyze_project(self) -> Dict[str, List[str]]:
        """üîç –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –º—É—Å–æ—Ä–∞"""
        print(f"{self.BLUE}üîç –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–µ–∫—Ç–∞...{self.END}")

        analysis = {
            'duplicate_files': [],
            'unused_files': [],
            'old_backups': [],
            'temp_files': [],
            'large_files': [],
            'broken_imports': [],
            'empty_directories': [],
            'migration_artifacts': []
        }

        # –ü–æ–∏—Å–∫ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        analysis['duplicate_files'] = self._find_duplicate_files()

        # –ü–æ–∏—Å–∫ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö —Ñ–∞–π–ª–æ–≤
        analysis['unused_files'] = self._find_unused_files()

        # –ü–æ–∏—Å–∫ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤
        analysis['old_backups'] = self._find_old_backups()

        # –ü–æ–∏—Å–∫ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        analysis['temp_files'] = self._find_temp_files()

        # –ü–æ–∏—Å–∫ –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
        analysis['large_files'] = self._find_large_files()

        # –ü–æ–∏—Å–∫ –ø—É—Å—Ç—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
        analysis['empty_directories'] = self._find_empty_directories()

        # –ü–æ–∏—Å–∫ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –º–∏–≥—Ä–∞—Ü–∏–∏
        analysis['migration_artifacts'] = self._find_migration_artifacts()

        return analysis


    def _find_duplicate_files(self) -> List[Dict[str, str]]:
        """üîç –ü–æ–∏—Å–∫ –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è —Ñ–∞–π–ª–æ–≤"""
        duplicates = []

        # –ò–∑–≤–µ—Å—Ç–Ω—ã–µ –¥—É–±–ª–∏–∫–∞—Ç—ã –≤ –ø—Ä–æ–µ–∫—Ç–µ
        known_duplicates = [
            ('main.py', 'main_old.py'),
            ('bot.py', 'hybrid_bot.py'),
            ('config.py', 'hybrid_config.py'),
            ('improved_bot.py', 'bot.py')
        ]

        for original, duplicate in known_duplicates:
            if (self.root_dir / original).exists() and (self.root_dir / duplicate).exists():
                duplicates.append({
                    'original': original,
                    'duplicate': duplicate,
                    'reason': 'Legacy —Ñ–∞–π–ª'
                })

        return duplicates


    def _find_unused_files(self) -> List[str]:
        """üîç –ü–æ–∏—Å–∫ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        unused = []

        # –§–∞–π–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–º–∏
        potentially_unused = [
            'test_*.py',
            '*_test.py',
            '*.pyc',
            '__pycache__/*',
            '*.log.old',
            '*.bak',
            'trades_manager.py',  # –£—Ç–∏–ª–∏—Ç–∞, –Ω–µ –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª
            'simple_analytics.py',  # –ï—Å–ª–∏ –µ—Å—Ç—å —É–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è
            'basic_*.py'  # –ë–∞–∑–æ–≤—ã–µ –≤–µ—Ä—Å–∏–∏
        ]

        for pattern in potentially_unused:
            files = glob.glob(str(self.root_dir / pattern), recursive=True)
            unused.extend([str(Path(f).relative_to(self.root_dir)) for f in files])

        return unused


    def _find_old_backups(self) -> List[str]:
        """üîç –ü–æ–∏—Å–∫ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤"""
        backups = []

        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –±—ç–∫–∞–ø–æ–≤
        backup_patterns = [
            '*_old.py',
            '*_backup.py',
            '*.old',
            '*.bak',
            'backup_*',
            '*_copy.py'
        ]

        for pattern in backup_patterns:
            files = glob.glob(str(self.root_dir / pattern))
            backups.extend([str(Path(f).relative_to(self.root_dir)) for f in files])

        # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –±—ç–∫–∞–ø–æ–≤
        backup_dirs = ['backup_before_migration', 'old_files', 'backups']
        for backup_dir in backup_dirs:
            if (self.root_dir / backup_dir).exists():
                backups.append(backup_dir)

        return backups


    def _find_temp_files(self) -> List[str]:
        """üîç –ü–æ–∏—Å–∫ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        temp_files = []

        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        temp_patterns = [
            '*.tmp',
            '*.temp',
            '.DS_Store',
            'Thumbs.db',
            '*.swp',
            '*.swo',
            '*~',
            '.pytest_cache/*',
            '__pycache__/*',
            '*.pyc'
        ]

        for pattern in temp_patterns:
            files = glob.glob(str(self.root_dir / pattern), recursive=True)
            temp_files.extend([str(Path(f).relative_to(self.root_dir)) for f in files])

        return temp_files


    def _find_large_files(self, size_limit_mb: int = 10) -> List[Dict[str, any]]:
        """üîç –ü–æ–∏—Å–∫ –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤"""
        large_files = []
        size_limit = size_limit_mb * 1024 * 1024  # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –±–∞–π—Ç—ã

        for file_path in self.root_dir.rglob('*'):
            if file_path.is_file():
                try:
                    file_size = file_path.stat().st_size
                    if file_size > size_limit:
                        large_files.append({
                            'path': str(file_path.relative_to(self.root_dir)),
                            'size_mb': file_size / (1024 * 1024),
                            'size_bytes': file_size
                        })
                except (OSError, PermissionError):
                    continue

        return sorted(large_files, key=lambda x: x['size_bytes'], reverse=True)


    def _find_empty_directories(self) -> List[str]:
        """üîç –ü–æ–∏—Å–∫ –ø—É—Å—Ç—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π"""
        empty_dirs = []

        for dir_path in self.root_dir.rglob('*'):
            if dir_path.is_dir():
                try:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø—É—Å—Ç–∞—è –ª–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è
                    if not any(dir_path.iterdir()):
                        empty_dirs.append(str(dir_path.relative_to(self.root_dir)))
                except (OSError, PermissionError):
                    continue

        return empty_dirs


    def _find_migration_artifacts(self) -> List[str]:
        """üîç –ü–æ–∏—Å–∫ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –º–∏–≥—Ä–∞—Ü–∏–∏"""
        artifacts = []

        # –§–∞–π–ª—ã –º–∏–≥—Ä–∞—Ü–∏–∏
        migration_patterns = [
            'migration_*.py',
            '*_migration.py',
            'auto_fix_patch.py',
            'migration_patch.py',
            'migration_report.json',
            'diagnostic_report.json'
        ]

        for pattern in migration_patterns:
            files = glob.glob(str(self.root_dir / pattern))
            artifacts.extend([str(Path(f).relative_to(self.root_dir)) for f in files])

        return artifacts


    def clean_project(self, analysis: Dict[str, List], interactive: bool = True) -> None:
        """üßπ –û—á–∏—Å—Ç–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞"""
        print(f"{self.YELLOW}üßπ –ù–∞—á–∏–Ω–∞–µ–º –æ—á–∏—Å—Ç–∫—É –ø—Ä–æ–µ–∫—Ç–∞...{self.END}")

        # –°–æ–∑–¥–∞–µ–º –±—ç–∫–∞–ø –ø–µ—Ä–µ–¥ –æ—á–∏—Å—Ç–∫–æ–π
        if interactive:
            create_backup = input(f"{self.BLUE}üíæ –°–æ–∑–¥–∞—Ç—å –±—ç–∫–∞–ø –ø–µ—Ä–µ–¥ –æ—á–∏—Å—Ç–∫–æ–π? (Y/n): {self.END}").lower()
            if create_backup != 'n':
                self._create_cleanup_backup()

        # –û—á–∏—â–∞–µ–º –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        if analysis['temp_files']:
            self._clean_temp_files(analysis['temp_files'], interactive)

        if analysis['duplicate_files']:
            self._clean_duplicates(analysis['duplicate_files'], interactive)

        if analysis['empty_directories']:
            self._clean_empty_directories(analysis['empty_directories'], interactive)

        if analysis['migration_artifacts']:
            self._clean_migration_artifacts(analysis['migration_artifacts'], interactive)

        if analysis['old_backups']:
            self._clean_old_backups(analysis['old_backups'], interactive)

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self._show_cleanup_stats()


    def _create_cleanup_backup(self) -> None:
        """üíæ –°–æ–∑–¥–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞ –ø–µ—Ä–µ–¥ –æ—á–∏—Å—Ç–∫–æ–π"""
        backup_dir = self.root_dir / f"cleanup_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        backup_dir.mkdir(exist_ok=True)

        # –ö–æ–ø–∏—Ä—É–µ–º –≤–∞–∂–Ω—ã–µ —Ñ–∞–π–ª—ã
        important_files = [
            '*.py',
            '*.json',
            '.env*',
            'requirements*.txt',
            'README*',
            'config/*'
        ]

        for pattern in important_files:
            files = glob.glob(str(self.root_dir / pattern))
            for file_path in files:
                if Path(file_path).is_file():
                    rel_path = Path(file_path).relative_to(self.root_dir)
                    dest_path = backup_dir / rel_path
                    dest_path.parent.mkdir(parents=True, exist_ok=True)
                    shutil.copy2(file_path, dest_path)

        print(f"{self.GREEN}üíæ –ë—ç–∫–∞–ø —Å–æ–∑–¥–∞–Ω: {backup_dir}{self.END}")


    def _clean_temp_files(self, temp_files: List[str], interactive: bool) -> None:
        """üóëÔ∏è –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        if not temp_files:
            return

        print(f"\n{self.YELLOW}üóëÔ∏è –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ ({len(temp_files)} –Ω–∞–π–¥–µ–Ω–æ):{self.END}")

        if interactive:
            print("–ù–∞–π–¥–µ–Ω—ã –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:")
            for file_path in temp_files[:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
                print(f"  ‚Ä¢ {file_path}")
            if len(temp_files) > 10:
                print(f"  ... –∏ –µ—â–µ {len(temp_files) - 10} —Ñ–∞–π–ª–æ–≤")

            confirm = input(f"{self.BLUE}–£–¥–∞–ª–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã? (Y/n): {self.END}").lower()
            if confirm == 'n':
                return

        for file_path in temp_files:
            try:
                full_path = self.root_dir / file_path
                if full_path.exists():
                    if full_path.is_file():
                        size = full_path.stat().st_size
                        full_path.unlink()
                        self.stats['files_removed'] += 1
                        self.stats['bytes_freed'] += size
                    elif full_path.is_dir():
                        shutil.rmtree(full_path)
                        self.stats['directories_removed'] += 1

                    print(f"  ‚úÖ –£–¥–∞–ª–µ–Ω: {file_path}")
            except Exception as e:
                print(f"  ‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è {file_path}: {e}")


    def _clean_duplicates(self, duplicates: List[Dict[str, str]], interactive: bool) -> None:
        """üóëÔ∏è –û—á–∏—Å—Ç–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"""
        if not duplicates:
            return

        print(f"\n{self.YELLOW}üóëÔ∏è –û—á–∏—Å—Ç–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ ({len(duplicates)} –Ω–∞–π–¥–µ–Ω–æ):{self.END}")

        for dup_info in duplicates:
            original = dup_info['original']
            duplicate = dup_info['duplicate']
            reason = dup_info['reason']

            print(f"  –î—É–±–ª–∏–∫–∞—Ç: {duplicate} (–æ—Ä–∏–≥–∏–Ω–∞–ª: {original}) - {reason}")

            if interactive:
                action = input(f"    –£–¥–∞–ª–∏—Ç—å {duplicate}? (y/N/s-skip): ").lower()
                if action == 's':
                    continue
                elif action != 'y':
                    continue

            try:
                duplicate_path = self.root_dir / duplicate
                if duplicate_path.exists():
                    size = duplicate_path.stat().st_size
                    duplicate_path.unlink()
                    self.stats['files_removed'] += 1
                    self.stats['duplicates_removed'] += 1
                    self.stats['bytes_freed'] += size
                    print(f"    ‚úÖ –£–¥–∞–ª–µ–Ω –¥—É–±–ª–∏–∫–∞—Ç: {duplicate}")
            except Exception as e:
                print(f"    ‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è {duplicate}: {e}")


    def _clean_empty_directories(self, empty_dirs: List[str], interactive: bool) -> None:
        """üóëÔ∏è –û—á–∏—Å—Ç–∫–∞ –ø—É—Å—Ç—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π"""
        if not empty_dirs:
            return

        print(f"\n{self.YELLOW}üóëÔ∏è –û—á–∏—Å—Ç–∫–∞ –ø—É—Å—Ç—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π ({len(empty_dirs)} –Ω–∞–π–¥–µ–Ω–æ):{self.END}")

        if interactive:
            print("–ù–∞–π–¥–µ–Ω—ã –ø—É—Å—Ç—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏:")
            for dir_path in empty_dirs:
                print(f"  ‚Ä¢ {dir_path}/")

            confirm = input(f"{self.BLUE}–£–¥–∞–ª–∏—Ç—å –ø—É—Å—Ç—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏? (Y/n): {self.END}").lower()
            if confirm == 'n':
                return

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≥–ª—É–±–∏–Ω–µ (—Å–Ω–∞—á–∞–ª–∞ —Å–∞–º—ã–µ –≥–ª—É–±–æ–∫–∏–µ)
        empty_dirs.sort(key=lambda x: len(Path(x).parts), reverse=True)

        for dir_path in empty_dirs:
            try:
                full_path = self.root_dir / dir_path
                if full_path.exists() and full_path.is_dir():
                    full_path.rmdir()
                    self.stats['directories_removed'] += 1
                    print(f"  ‚úÖ –£–¥–∞–ª–µ–Ω–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {dir_path}/")
            except Exception as e:
                print(f"  ‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è {dir_path}: {e}")


    def _clean_migration_artifacts(self, artifacts: List[str], interactive: bool) -> None:
        """üóëÔ∏è –û—á–∏—Å—Ç–∫–∞ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –º–∏–≥—Ä–∞—Ü–∏–∏"""
        if not artifacts:
            return

        print(f"\n{self.YELLOW}üóëÔ∏è –û—á–∏—Å—Ç–∫–∞ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –º–∏–≥—Ä–∞—Ü–∏–∏ ({len(artifacts)} –Ω–∞–π–¥–µ–Ω–æ):{self.END}")

        if interactive:
            print("–ù–∞–π–¥–µ–Ω—ã –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –º–∏–≥—Ä–∞—Ü–∏–∏:")
            for artifact in artifacts:
                print(f"  ‚Ä¢ {artifact}")

            confirm = input(f"{self.BLUE}–£–¥–∞–ª–∏—Ç—å –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –º–∏–≥—Ä–∞—Ü–∏–∏? (Y/n): {self.END}").lower()
            if confirm == 'n':
                return

        for artifact in artifacts:
            try:
                artifact_path = self.root_dir / artifact
                if artifact_path.exists():
                    size = artifact_path.stat().st_size
                    artifact_path.unlink()
                    self.stats['files_removed'] += 1
                    self.stats['bytes_freed'] += size
                    print(f"  ‚úÖ –£–¥–∞–ª–µ–Ω –∞—Ä—Ç–µ—Ñ–∞–∫—Ç: {artifact}")
            except Exception as e:
                print(f"  ‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è {artifact}: {e}")


    def _clean_old_backups(self, backups: List[str], interactive: bool) -> None:
        """üóëÔ∏è –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤"""
        if not backups:
            return

        print(f"\n{self.YELLOW}üóëÔ∏è –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤ ({len(backups)} –Ω–∞–π–¥–µ–Ω–æ):{self.END}")

        if interactive:
            print("–ù–∞–π–¥–µ–Ω—ã —Å—Ç–∞—Ä—ã–µ –±—ç–∫–∞–ø—ã:")
            for backup in backups:
                print(f"  ‚Ä¢ {backup}")

            confirm = input(f"{self.BLUE}–£–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—ã–µ –±—ç–∫–∞–ø—ã? (y/N): {self.END}").lower()
            if confirm != 'y':
                return

        for backup in backups:
            try:
                backup_path = self.root_dir / backup
                if backup_path.exists():
                    if backup_path.is_file():
                        size = backup_path.stat().st_size
                        backup_path.unlink()
                        self.stats['files_removed'] += 1
                        self.stats['bytes_freed'] += size
                    elif backup_path.is_dir():
                        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ø–µ—Ä–µ–¥ —É–¥–∞–ª–µ–Ω–∏–µ–º
                        total_size = sum(f.stat().st_size for f in backup_path.rglob('*') if f.is_file())
                        shutil.rmtree(backup_path)
                        self.stats['directories_removed'] += 1
                        self.stats['bytes_freed'] += total_size

                    print(f"  ‚úÖ –£–¥–∞–ª–µ–Ω –±—ç–∫–∞–ø: {backup}")
            except Exception as e:
                print(f"  ‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è {backup}: {e}")


    def _show_cleanup_stats(self) -> None:
        """üìä –ü–æ–∫–∞–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ—á–∏—Å—Ç–∫–∏"""
        print(f"\n{self.GREEN}üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –û–ß–ò–°–¢–ö–ò{self.END}")
        print("=" * 30)
        print(f"–£–¥–∞–ª–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {self.stats['files_removed']}")
        print(f"–£–¥–∞–ª–µ–Ω–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π: {self.stats['directories_removed']}")
        print(f"–£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {self.stats['duplicates_removed']}")
        print(f"–û—Å–≤–æ–±–æ–∂–¥–µ–Ω–æ –º–µ—Å—Ç–∞: {self.stats['bytes_freed'] / (1024 * 1024):.2f} MB")


    def show_analysis_report(self, analysis: Dict[str, List]) -> None:
        """üìã –ü–æ–∫–∞–∑ –æ—Ç—á–µ—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞"""
        print(f"\n{self.BLUE}üìã –û–¢–ß–ï–¢ –ê–ù–ê–õ–ò–ó–ê –ü–†–û–ï–ö–¢–ê{self.END}")
        print("=" * 40)

        categories = [
            ('duplicate_files', '–î—É–±–ª–∏–∫–∞—Ç—ã —Ñ–∞–π–ª–æ–≤', 'üîÑ'),
            ('unused_files', '–ù–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —Ñ–∞–π–ª—ã', '‚ùå'),
            ('old_backups', '–°—Ç–∞—Ä—ã–µ –±—ç–∫–∞–ø—ã', 'üì¶'),
            ('temp_files', '–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã', 'üóëÔ∏è'),
            ('large_files', '–ë–æ–ª—å—à–∏–µ —Ñ–∞–π–ª—ã', 'üìä'),
            ('empty_directories', '–ü—É—Å—Ç—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏', 'üìÅ'),
            ('migration_artifacts', '–ê—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –º–∏–≥—Ä–∞—Ü–∏–∏', 'üîÑ')
        ]

        total_issues = 0

        for key, title, emoji in categories:
            items = analysis[key]
            if items:
                print(f"\n{emoji} {title}: {len(items)}")

                if key == 'large_files':
                    for item in items[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-5 –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
                        print(f"  ‚Ä¢ {item['path']} ({item['size_mb']:.2f} MB)")
                    if len(items) > 5:
                        print(f"  ... –∏ –µ—â–µ {len(items) - 5} —Ñ–∞–π–ª–æ–≤")
                elif key == 'duplicate_files':
                    for item in items:
                        print(f"  ‚Ä¢ {item['duplicate']} (–¥—É–±–ª–∏–∫–∞—Ç {item['original']})")
                else:
                    for item in items[:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
                        print(f"  ‚Ä¢ {item}")
                    if len(items) > 10:
                        print(f"  ... –∏ –µ—â–µ {len(items) - 10} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")

                total_issues += len(items)
            else:
                print(f"{emoji} {title}: ‚úÖ –ß–∏—Å—Ç–æ")

        print(f"\n{'=' * 40}")
        print(f"–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º: {total_issues}")

        if total_issues > 0:
            print(f"{self.YELLOW}üí° –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Å—Ç–∏ –æ—á–∏—Å—Ç–∫—É{self.END}")
        else:
            print(f"{self.GREEN}üéâ –ü—Ä–æ–µ–∫—Ç —É–∂–µ —á–∏—Å—Ç—ã–π!{self.END}")


    def run_interactive_cleanup(self) -> None:
        """üöÄ –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞"""
        print(f"{self.BLUE}üßπ –ò–ù–¢–ï–†–ê–ö–¢–ò–í–ù–ê–Ø –û–ß–ò–°–¢–ö–ê –¢–û–†–ì–û–í–û–ì–û –ë–û–¢–ê{self.END}")
        print("=" * 50)

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–µ–∫—Ç
        analysis = self.analyze_project()

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Ç—á–µ—Ç
        self.show_analysis_report(analysis)

        # –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º –æ—á–∏—Å—Ç–∫—É
        total_issues = sum(len(items) for items in analysis.values())
        if total_issues > 0:
            print(f"\n{self.YELLOW}–ù–∞–π–¥–µ–Ω–æ {total_issues} –ø—Ä–æ–±–ª–µ–º –¥–ª—è –æ—á–∏—Å—Ç–∫–∏{self.END}")
            proceed = input(f"{self.BLUE}–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Å –æ—á–∏—Å—Ç–∫–æ–π? (Y/n): {self.END}").lower()

            if proceed != 'n':
                self.clean_project(analysis, interactive=True)
            else:
                print("–û—á–∏—Å—Ç–∫–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞")
        else:
            print(f"{self.GREEN}–ü—Ä–æ–µ–∫—Ç —É–∂–µ —á–∏—Å—Ç—ã–π! üéâ{self.END}")


def main():
    """üöÄ –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    cleaner = BotCleaner()

    try:
        cleaner.run_interactive_cleanup()
    except KeyboardInterrupt:
        print(f"\n{cleaner.YELLOW}‚å®Ô∏è –û—á–∏—Å—Ç–∫–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º{cleaner.END}")
    except Exception as e:
        print(f"\n{cleaner.RED}‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏: {e}{cleaner.END}")
        cleaner.logger.error(f"Cleanup error: {e}")


if __name__ == "__main__":
    main()