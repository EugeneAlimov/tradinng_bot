#!/usr/bin/env python3
"""üìä –ò–Ω–≤–µ–Ω—Ç–∞—Ä–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Ç–æ—Ä–≥–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã - –≠—Ç–∞–ø 1.1"""

import os
import ast
import inspect
from pathlib import Path
from typing import Dict, List, Any, Set, Tuple
from dataclasses import dataclass, field
from collections import defaultdict


@dataclass
class ComponentInfo:
    """üì¶ –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–µ"""
    name: str
    file_path: str
    type: str  # class, function, module
    dependencies: Set[str] = field(default_factory=set)
    methods: List[str] = field(default_factory=list)
    attributes: List[str] = field(default_factory=list)
    imports: Set[str] = field(default_factory=set)
    size_lines: int = 0
    complexity_score: int = 0
    is_legacy: bool = True
    is_critical: bool = False


@dataclass
class DependencyGraph:
    """üîó –ì—Ä–∞—Ñ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"""
    nodes: Dict[str, ComponentInfo] = field(default_factory=dict)
    edges: Dict[str, Set[str]] = field(default_factory=lambda: defaultdict(set))
    reverse_edges: Dict[str, Set[str]] = field(default_factory=lambda: defaultdict(set))


class ComponentInventory:
    """üìä –ò–Ω–≤–µ–Ω—Ç–∞—Ä–∏–∑–∞—Ç–æ—Ä –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
    
    def __init__(self, root_path: str = "."):
        self.root_path = Path(root_path)
        self.components: Dict[str, ComponentInfo] = {}
        self.dependency_graph = DependencyGraph()
        
        # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (—è–¥—Ä–æ —Å–∏—Å—Ç–µ–º—ã)
        self.critical_components = {
            'TradingBot', 'HybridTradingBot', 'ImprovedTradingBot',
            'TradeOrchestrator', 'StrategyManager', 'APIService',
            'PositionManager', 'RiskManager', 'ExmoAPIClient'
        }
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è legacy –∫–æ–¥–∞
        self.legacy_patterns = {
            'improved_bot.py', 'hybrid_bot.py', 'bot.py',
            'trade_orchestrator.py', 'strategies.py'
        }
    
    def analyze_project(self) -> Dict[str, Any]:
        """üîç –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–µ–∫—Ç–∞"""
        print("üìä –ù–∞—á–∏–Ω–∞–µ–º –∏–Ω–≤–µ–Ω—Ç–∞—Ä–∏–∑–∞—Ü–∏—é –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤...")
        
        # 1. –°–∫–∞–Ω–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã
        self._scan_python_files()
        
        # 2. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
        self._analyze_dependencies()
        
        # 3. –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ
        self._build_dependency_graph()
        
        # 4. –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
        metrics = self._calculate_metrics()
        
        # 5. –í—ã—è–≤–ª—è–µ–º –ø—Ä–æ–±–ª–µ–º—ã
        issues = self._identify_issues()
        
        # 6. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
        report = self._generate_report(metrics, issues)
        
        print("‚úÖ –ò–Ω–≤–µ–Ω—Ç–∞—Ä–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        return report
    
    def _scan_python_files(self) -> None:
        """üìÇ –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ Python —Ñ–∞–π–ª–æ–≤"""
        python_files = list(self.root_path.rglob("*.py"))
        excluded_patterns = {'__pycache__', '.git', 'venv', 'env'}
        
        for file_path in python_files:
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            if any(pattern in str(file_path) for pattern in excluded_patterns):
                continue
                
            try:
                self._analyze_file(file_path)
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {file_path}: {e}")
    
    def _analyze_file(self, file_path: Path) -> None:
        """üìÑ –ê–Ω–∞–ª–∏–∑ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            tree = ast.parse(content)
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª–∞—Å—Å—ã
            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef):
                    self._analyze_class(node, file_path, content)
                elif isinstance(node, ast.FunctionDef):
                    if not self._is_method(node, tree):
                        self._analyze_function(node, file_path)
                        
        except SyntaxError as e:
            print(f"‚ö†Ô∏è –°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ {file_path}: {e}")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {file_path}: {e}")
    
    def _analyze_class(self, node: ast.ClassDef, file_path: Path, content: str) -> None:
        """üèóÔ∏è –ê–Ω–∞–ª–∏–∑ –∫–ª–∞—Å—Å–∞"""
        component_info = ComponentInfo(
            name=node.name,
            file_path=str(file_path),
            type="class",
            size_lines=len(content.split('\n')),
            is_legacy=file_path.name in self.legacy_patterns,
            is_critical=node.name in self.critical_components
        )
        
        # –ú–µ—Ç–æ–¥—ã
        for item in node.body:
            if isinstance(item, ast.FunctionDef):
                component_info.methods.append(item.name)
        
        # –ê—Ç—Ä–∏–±—É—Ç—ã (–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ)
        for item in node.body:
            if isinstance(item, ast.Assign):
                for target in item.targets:
                    if isinstance(target, ast.Name):
                        component_info.attributes.append(target.id)
        
        # –ë–∞–∑–æ–≤—ã–µ –∫–ª–∞—Å—Å—ã (–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏)
        for base in node.bases:
            if isinstance(base, ast.Name):
                component_info.dependencies.add(base.id)
        
        # –ò–º–ø–æ—Ä—Ç—ã –∏–∑ —Ñ–∞–π–ª–∞
        component_info.imports = self._extract_imports(file_path)
        
        # –°–ª–æ–∂–Ω–æ—Å—Ç—å (–ø—Ä–∏–º–µ—Ä–Ω–∞—è)
        component_info.complexity_score = self._calculate_complexity(node)
        
        self.components[f"{file_path.stem}.{node.name}"] = component_info
    
    def _analyze_function(self, node: ast.FunctionDef, file_path: Path) -> None:
        """‚öôÔ∏è –ê–Ω–∞–ª–∏–∑ —Ñ—É–Ω–∫—Ü–∏–∏"""
        component_info = ComponentInfo(
            name=node.name,
            file_path=str(file_path),
            type="function",
            is_legacy=file_path.name in self.legacy_patterns,
            complexity_score=len(node.body)
        )
        
        self.components[f"{file_path.stem}.{node.name}"] = component_info
    
    def _extract_imports(self, file_path: Path) -> Set[str]:
        """üì• –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–º–ø–æ—Ä—Ç–æ–≤"""
        imports = set()
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            tree = ast.parse(content)
            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        imports.add(alias.name)
                elif isinstance(node, ast.ImportFrom):
                    if node.module:
                        imports.add(node.module)
                        
        except Exception:
            pass
            
        return imports
    
    def _is_method(self, node: ast.FunctionDef, tree: ast.Module) -> bool:
        """üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ—É–Ω–∫—Ü–∏—è –º–µ—Ç–æ–¥–æ–º –∫–ª–∞—Å—Å–∞"""
        for parent in ast.walk(tree):
            if isinstance(parent, ast.ClassDef):
                if node in parent.body:
                    return True
        return False
    
    def _calculate_complexity(self, node: ast.AST) -> int:
        """üìä –†–∞—Å—á–µ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ (McCabe)"""
        complexity = 1  # –ë–∞–∑–æ–≤–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å
        
        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.While, ast.For, ast.With)):
                complexity += 1
            elif isinstance(child, ast.Try):
                complexity += len(child.handlers)
            elif isinstance(child, ast.BoolOp):
                complexity += len(child.values) - 1
                
        return complexity
    
    def _analyze_dependencies(self) -> None:
        """üîó –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –º–µ–∂–¥—É –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏"""
        for comp_name, component in self.components.items():
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–º–ø–æ—Ä—Ç—ã –∫–∞–∫ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
            for import_name in component.imports:
                # –ò—â–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
                for other_name, other_comp in self.components.items():
                    if (import_name in other_comp.file_path or 
                        import_name == other_comp.name):
                        component.dependencies.add(other_name)
    
    def _build_dependency_graph(self) -> None:
        """üï∏Ô∏è –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"""
        self.dependency_graph.nodes = self.components.copy()
        
        for comp_name, component in self.components.items():
            for dep in component.dependencies:
                if dep in self.components:
                    self.dependency_graph.edges[comp_name].add(dep)
                    self.dependency_graph.reverse_edges[dep].add(comp_name)
    
    def _calculate_metrics(self) -> Dict[str, Any]:
        """üìà –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫"""
        total_components = len(self.components)
        legacy_components = sum(1 for c in self.components.values() if c.is_legacy)
        critical_components = sum(1 for c in self.components.values() if c.is_critical)
        
        # –°–ª–æ–∂–Ω–æ—Å—Ç—å
        total_complexity = sum(c.complexity_score for c in self.components.values())
        avg_complexity = total_complexity / max(total_components, 1)
        
        # –†–∞–∑–º–µ—Ä—ã
        total_lines = sum(c.size_lines for c in self.components.values())
        avg_size = total_lines / max(total_components, 1)
        
        # –°–≤—è–∑–∞–Ω–Ω–æ—Å—Ç—å
        total_dependencies = sum(len(c.dependencies) for c in self.components.values())
        avg_dependencies = total_dependencies / max(total_components, 1)
        
        return {
            'total_components': total_components,
            'legacy_components': legacy_components,
            'critical_components': critical_components,
            'legacy_percentage': (legacy_components / max(total_components, 1)) * 100,
            'total_complexity': total_complexity,
            'avg_complexity': round(avg_complexity, 2),
            'total_lines': total_lines,
            'avg_component_size': round(avg_size, 2),
            'total_dependencies': total_dependencies,
            'avg_dependencies': round(avg_dependencies, 2),
            'coupling_ratio': round(avg_dependencies / max(total_components, 1), 3)
        }
    
    def _identify_issues(self) -> Dict[str, List[str]]:
        """üö® –í—ã—è–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º"""
        issues = {
            'high_complexity': [],
            'large_components': [],
            'high_coupling': [],
            'circular_dependencies': [],
            'missing_dependencies': [],
            'legacy_critical': []
        }
        
        for name, component in self.components.items():
            # –í—ã—Å–æ–∫–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å
            if component.complexity_score > 20:
                issues['high_complexity'].append(f"{name} (—Å–ª–æ–∂–Ω–æ—Å—Ç—å: {component.complexity_score})")
            
            # –ë–æ–ª—å—à–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
            if component.size_lines > 500:
                issues['large_components'].append(f"{name} ({component.size_lines} —Å—Ç—Ä–æ–∫)")
            
            # –í—ã—Å–æ–∫–∞—è —Å–≤—è–∑–∞–Ω–Ω–æ—Å—Ç—å
            if len(component.dependencies) > 10:
                issues['high_coupling'].append(f"{name} ({len(component.dependencies)} –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π)")
            
            # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π legacy –∫–æ–¥
            if component.is_critical and component.is_legacy:
                issues['legacy_critical'].append(name)
        
        # –ü–æ–∏—Å–∫ —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π)
        issues['circular_dependencies'] = self._find_circular_dependencies()
        
        return issues
    
    def _find_circular_dependencies(self) -> List[str]:
        """üîÑ –ü–æ–∏—Å–∫ —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"""
        cycles = []
        visited = set()
        path = []
        
        def dfs(node: str) -> None:
            if node in path:
                cycle_start = path.index(node)
                cycle = " -> ".join(path[cycle_start:] + [node])
                cycles.append(cycle)
                return
            
            if node in visited:
                return
                
            visited.add(node)
            path.append(node)
            
            for neighbor in self.dependency_graph.edges.get(node, []):
                dfs(neighbor)
            
            path.pop()
        
        for node in self.components:
            if node not in visited:
                dfs(node)
        
        return cycles[:5]  # –ü–µ—Ä–≤—ã–µ 5 —Ü–∏–∫–ª–æ–≤
    
    def _generate_report(self, metrics: Dict[str, Any], issues: Dict[str, List[str]]) -> Dict[str, Any]:
        """üìã –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞"""
        
        # –¢–æ–ø –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –ø–æ —Ä–∞–∑–ª–∏—á–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º
        top_complex = sorted(
            self.components.items(),
            key=lambda x: x[1].complexity_score,
            reverse=True
        )[:5]
        
        top_large = sorted(
            self.components.items(),
            key=lambda x: x[1].size_lines,
            reverse=True
        )[:5]
        
        top_coupled = sorted(
            self.components.items(),
            key=lambda x: len(x[1].dependencies),
            reverse=True
        )[:5]
        
        return {
            'timestamp': str(Path.cwd()),
            'metrics': metrics,
            'issues': issues,
            'top_rankings': {
                'most_complex': [(name, comp.complexity_score) for name, comp in top_complex],
                'largest': [(name, comp.size_lines) for name, comp in top_large],
                'most_coupled': [(name, len(comp.dependencies)) for name, comp in top_coupled]
            },
            'components_by_type': {
                'classes': [name for name, comp in self.components.items() if comp.type == 'class'],
                'functions': [name for name, comp in self.components.items() if comp.type == 'function']
            },
            'critical_path': self._identify_critical_path(),
            'migration_recommendations': self._generate_migration_recommendations()
        }
    
    def _identify_critical_path(self) -> List[str]:
        """üéØ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø—É—Ç–∏"""
        critical_components = [
            name for name, comp in self.components.items() 
            if comp.is_critical
        ]
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π (–≤–∞–∂–Ω–æ—Å—Ç—å)
        critical_path = sorted(
            critical_components,
            key=lambda x: len(self.dependency_graph.reverse_edges.get(x, set())),
            reverse=True
        )
        
        return critical_path[:10]
    
    def _generate_migration_recommendations(self) -> List[str]:
        """üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –º–∏–≥—Ä–∞—Ü–∏–∏"""
        recommendations = []
        
        # –ù–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞
        if len([c for c in self.components.values() if c.is_legacy]) > 10:
            recommendations.append("–°–æ–∑–¥–∞—Ç—å –∞–¥–∞–ø—Ç–µ—Ä—ã –¥–ª—è legacy –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤")
        
        if any(len(c.dependencies) > 15 for c in self.components.values()):
            recommendations.append("–†–∞–∑–±–∏—Ç—å –≤—ã—Å–æ–∫–æ—Å–≤—è–∑–∞–Ω–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã")
        
        if any(c.size_lines > 1000 for c in self.components.values()):
            recommendations.append("–†–∞–∑–±–∏—Ç—å –±–æ–ª—å—à–∏–µ –∫–ª–∞—Å—Å—ã –Ω–∞ –º–æ–¥—É–ª–∏")
        
        recommendations.extend([
            "–†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Å–ª–æ–π –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–π (interfaces)",
            "–°–æ–∑–¥–∞—Ç—å dependency injection –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä", 
            "–î–æ–±–∞–≤–∏—Ç—å unit —Ç–µ—Å—Ç—ã –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤",
            "–í–Ω–µ–¥—Ä–∏—Ç—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥"
        ])
        
        return recommendations
    
    def save_report(self, report: Dict[str, Any], output_file: str = "component_inventory_report.json") -> None:
        """üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞"""
        import json
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º sets –≤ lists –¥–ª—è JSON —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏
        def convert_sets(obj):
            if isinstance(obj, set):
                return list(obj)
            elif isinstance(obj, dict):
                return {k: convert_sets(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert_sets(item) for item in obj]
            return obj
        
        json_report = convert_sets(report)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(json_report, f, indent=2, ensure_ascii=False)
        
        print(f"üìÑ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {output_file}")


def main():
    """üöÄ –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    inventory = ComponentInventory()
    report = inventory.analyze_project()
    
    # –ü–µ—á–∞—Ç–∞–µ–º –∫—Ä–∞—Ç–∫–∏–π –æ—Ç—á–µ—Ç
    print("\n" + "="*60)
    print("üìä –ö–†–ê–¢–ö–ò–ô –û–¢–ß–ï–¢ –ü–û –ö–û–ú–ü–û–ù–ï–ù–¢–ê–ú")
    print("="*60)
    
    metrics = report['metrics']
    print(f"üì¶ –í—Å–µ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤: {metrics['total_components']}")
    print(f"üìú Legacy –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤: {metrics['legacy_components']} ({metrics['legacy_percentage']:.1f}%)")
    print(f"üéØ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö: {metrics['critical_components']}")
    print(f"üìè –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä: {metrics['avg_component_size']:.0f} —Å—Ç—Ä–æ–∫")
    print(f"üîó –°—Ä–µ–¥–Ω—è—è —Å–≤—è–∑–∞–Ω–Ω–æ—Å—Ç—å: {metrics['avg_dependencies']:.2f}")
    print(f"‚öôÔ∏è –û–±—â–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å: {metrics['total_complexity']}")
    
    # –ü—Ä–æ–±–ª–µ–º—ã
    issues = report['issues']
    print(f"\nüö® –í–´–Ø–í–õ–ï–ù–ù–´–ï –ü–†–û–ë–õ–ï–ú–´:")
    for issue_type, items in issues.items():
        if items:
            print(f"  {issue_type}: {len(items)}")
    
    # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –ø—É—Ç—å
    print(f"\nüéØ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –ü–£–¢–¨:")
    for i, comp in enumerate(report['critical_path'][:5], 1):
        print(f"  {i}. {comp}")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    for i, rec in enumerate(report['migration_recommendations'][:5], 1):
        print(f"  {i}. {rec}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç
    inventory.save_report(report)
    
    return report


if __name__ == "__main__":
    main()